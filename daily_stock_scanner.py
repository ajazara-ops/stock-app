import yfinance as yf
import pandas as pd
import json
import time
import ssl
import requests
import xml.etree.ElementTree as ET
import math
import os
import sys
import re
import argparse 
from collections import Counter
from datetime import datetime, timedelta

# SSL ì¸ì¦ì„œ ì˜¤ë¥˜ ë°©ì§€
ssl._create_default_https_context = ssl._create_unverified_context

# í´ë” ê²½ë¡œ ìƒìˆ˜ ì •ì˜
DAILY_DATA_DIR = 'daily_data'
WEEKLY_REPORT_DIR = 'weekly_reports'

# --- [ì•ˆì „ì¥ì¹˜] ---
def safe_float(val, default=0.0):
    try:
        if val is None or val == "" or str(val).strip() == "-": return default
        f = float(val)
        if math.isnan(f) or math.isinf(f): return default
        return f
    except: return default

# --- [ì•Œë¦¼ ì „ì†¡ í•¨ìˆ˜] ---
def send_push_notification(title, message):
    # âœ… ì‚¬ìš©ìë‹˜ì˜ í‘¸ì‹œ í† í° (ì´ ë¶€ë¶„ì´ ì•± ë¡œê·¸ì˜ í† í°ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤!)
    user_push_tokens = ["ExponentPushToken[A1pSo_HgzWn_M2-94c5Pr2]"] 

    if not user_push_tokens:
        print(f"âš ï¸ [ì•Œë¦¼ ì‹œë®¬ë ˆì´ì…˜] ì „ì†¡í•  í† í° ì—†ìŒ.\nì œëª©: {title}\në‚´ìš©: {message}")
        return

    url = "https://exp.host/--/api/v2/push/send"
    headers = {
        "host": "exp.host",
        "accept": "application/json",
        "accept-encoding": "gzip, deflate",
        "content-type": "application/json"
    }

    print(f"ğŸ“¨ ì•Œë¦¼ ì „ì†¡ ì‹œë„: {title}")
    for token in user_push_tokens:
        payload = {
            "to": token,
            "title": title,
            "body": message,
            "sound": "default",
            "priority": "high"
        }
        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            if response.status_code == 200:
                print(f"  âœ… ì „ì†¡ ì„±ê³µ: {response.json()}")
            else:
                print(f"  âŒ ì „ì†¡ ì‹¤íŒ¨: {response.text}")
        except Exception as e:
            print(f"  âŒ ì „ì†¡ ì—ëŸ¬: {e}")

# ... (ì¤‘ê°„ ë¶„ì„ í•¨ìˆ˜ë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ë¯€ë¡œ ìƒëµí•˜ì§€ ì•Šê³  ì „ì²´ ì½”ë“œ ì œê³µ) ...
# --- [ì–´ì œ ì¶”ì²œ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°] ---
def get_latest_recommendation_ids():
    if not os.path.exists(DAILY_DATA_DIR): return set()
    files = sorted([f for f in os.listdir(DAILY_DATA_DIR) if f.endswith('_daily.json')], reverse=True)
    if not files: return set()
    try:
        with open(f"{DAILY_DATA_DIR}/{files[0]}", 'r', encoding='utf-8') as f:
            data = json.load(f)
            return {s['id'] for s in data.get('stocks', [])}
    except:
        return set()

def get_previous_recommendation_ids(target_date_str):
    if not os.path.exists(DAILY_DATA_DIR): return set()
    target_date = datetime.strptime(target_date_str, "%Y-%m-%d")
    files = sorted([f for f in os.listdir(DAILY_DATA_DIR) if f.endswith('_daily.json')], reverse=True)
    for f in files:
        file_date_str = f.split('_')[0]
        try:
            file_date = datetime.strptime(file_date_str, "%Y-%m-%d")
            if file_date < target_date:
                with open(f"{DAILY_DATA_DIR}/{f}", 'r', encoding='utf-8') as file:
                    data = json.load(file)
                    return {s['id'] for s in data.get('stocks', [])}
        except:
            continue
    return set()

def analyze_market_condition(target_date=None):
    print("ğŸŒ ê¸€ë¡œë²Œ ì‹œì¥ ìƒí™© ë¶„ì„ ì¤‘...")
    markets = {'US': {'ticker': '^GSPC', 'name': 'S&P 500'}, 'KR': {'ticker': '^KS11', 'name': 'KOSPI'}, 'VIX': {'ticker': '^VIX', 'name': 'ê³µí¬ì§€ìˆ˜'}}
    market_status = {}
    for key, info in markets.items():
        try:
            ticker = yf.Ticker(info['ticker'])
            hist = ticker.history(period="2y") 
            if target_date:
                hist.index = hist.index.tz_localize(None) 
                hist = hist[hist.index.strftime('%Y-%m-%d') <= target_date]
            if len(hist) < 2:
                market_status[key] = {'status': 'UNKNOWN', 'change': 0.0, 'current': 0.0, 'message': 'ë°ì´í„° ì—†ìŒ'}
                continue
            current = hist['Close'].iloc[-1]; prev = hist['Close'].iloc[-2]
            change_pct = ((current - prev) / prev) * 100
            status, message = "NEUTRAL", ""
            if key == 'VIX':
                if current >= 30: status, message = "PANIC", "ê·¹ë„ì˜ ê³µí¬ ğŸ˜±"
                elif current >= 20: status, message = "BAD", "ê³µí¬ êµ¬ê°„ ğŸ˜¨"
                elif current <= 15: status, message = "VERY_GOOD", "ì‹œì¥ ê³¼ì—´ ğŸ¤‘"
                else: status, message = "NEUTRAL", "ì•ˆì •ì  ğŸ˜Œ"
            else:
                if change_pct >= 1.0: status, message = "VERY_GOOD", "ê°•í•œ ìƒìŠ¹ ğŸ”¥"
                elif change_pct >= 0.2: status, message = "GOOD", "ìƒìŠ¹ì„¸ ğŸ“ˆ"
                elif change_pct > -0.5: status, message = "NEUTRAL", "ë³´í•©ì„¸ â–"
                elif change_pct > -1.5: status, message = "BAD", "í•˜ë½ì„¸ â˜ï¸"
                else: status, message = "PANIC", "í­ë½ ê²½ê³  â›ˆï¸"
            market_status[key] = {'name': info['name'], 'current': safe_float(round(current, 2)), 'change': safe_float(round(change_pct, 2)), 'status': status, 'message': message}
        except Exception as e: 
            market_status[key] = {'status': 'UNKNOWN', 'change': 0.0, 'message': 'ë¶„ì„ ì‹¤íŒ¨'}
    return market_status

def get_sp500_tickers():
    try:
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers)
        table = pd.read_html(response.text)
        tickers = table[0]['Symbol'].tolist()
        return [t.replace('.', '-') for t in tickers]
    except: return ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'TSLA', 'META']

def get_nasdaq100_tickers():
    try:
        url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers)
        tables = pd.read_html(response.text)
        for table in tables:
            if 'Ticker' in table.columns:
                return [str(t).replace('.', '-') for t in table['Ticker'].tolist()]
            elif 'Symbol' in table.columns:
                return [str(t).replace('.', '-') for t in table['Symbol'].tolist()]
        return []
    except Exception as e:
        return []

def get_korea_tickers():
    tickers = []
    try:
        url = 'https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page=1'
        res = requests.get(url)
        codes = re.findall(r'href="/item/main.naver\?code=(\d{6})"', res.text)
        seen = set()
        unique_codes = [x for x in codes if not (x in seen or seen.add(x))]
        for code in unique_codes[:50]: tickers.append(f"{code}.KS")
    except Exception as e: pass
    try:
        url = 'https://finance.naver.com/sise/sise_market_sum.naver?sosok=1&page=1'
        res = requests.get(url)
        codes = re.findall(r'href="/item/main.naver\?code=(\d{6})"', res.text)
        seen = set()
        unique_codes = [x for x in codes if not (x in seen or seen.add(x))]
        for code in unique_codes[:50]: tickers.append(f"{code}.KQ")
    except Exception as e: pass
    if not tickers:
        return ['005930.KS', '000660.KS', '373220.KS', '005380.KS', '000270.KS', '068270.KS', '005490.KS', '035420.KS']
    return tickers

def get_kr_fundamental(ticker):
    try:
        code = ticker.split('.')[0]
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        dfs = pd.read_html(url, encoding='euc-kr')
        fin_df = None
        for df in dfs:
            if df.shape[1] > 1 and 'ì˜ì—…ì´ìµë¥ ' in str(df.iloc[:, 0].values):
                fin_df = df
                break
        if fin_df is None: return None
        fin_df.set_index(fin_df.columns[0], inplace=True)
        target_col = fin_df.columns[-1] 
        def get_val(row_name):
            try:
                rows = fin_df[fin_df.index.str.contains(row_name, na=False)]
                if len(rows) > 0:
                    val = rows.iloc[0][target_col]
                    return safe_float(val, None) 
                return None
            except: return None
        op_margin = get_val('ì˜ì—…ì´ìµë¥ ')
        per = get_val('PER')
        pbr = get_val('PBR')
        return {
            "op_margin": op_margin / 100.0 if op_margin else None, 
            "per": per,
            "pbr": pbr,
            "rev_growth": None 
        }
    except: return None

def get_news_from_google_kr(ticker):
    try:
        url = f"https://news.google.com/rss/search?q={ticker.split('.')[0]}+ì£¼ê°€&hl=ko&gl=KR&ceid=KR:ko"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=3); root = ET.fromstring(response.content)
        return [{'title': item.find('title').text, 'link': item.find('link').text, 'publisher': item.find('source').text} for item in root.findall('./channel/item')[:3]]
    except: return []

def get_news_from_google_us(ticker):
    try:
        url = f"https://news.google.com/rss/search?q={ticker}+stock&hl=en-US&gl=US&ceid=US:en"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=3); root = ET.fromstring(response.content)
        return [{'title': item.find('title').text, 'link': item.find('link').text, 'publisher': item.find('source').text} for item in root.findall('./channel/item')[:3]]
    except: return []

def analyze_news_sentiment(news_list):
    analyzed = []
    pos = ['surge', 'jump', 'soar', 'gain', 'profit', 'buy', 'growth', 'record', 'upgrade', 'ê¸‰ë“±', 'ìƒìŠ¹', 'í˜¸ì¬', 'ì¦ê°€', 'ê°œì„ ', 'ë§¤ìˆ˜', 'ì²´ê²°', 'ì„±ì¥', 'ìµœê³ ']
    neg = ['drop', 'fall', 'plunge', 'loss', 'miss', 'sell', 'crash', 'downgrade', 'lawsuit', 'ê¸‰ë½', 'í•˜ë½', 'ì•…ì¬', 'ê°ì†Œ', 'ë¶€ì§„', 'ë§¤ë„', 'ì ì', 'ìš°ë ¤', 'ì†Œì†¡']
    for n in news_list:
        t = n.get('title', '').strip(); 
        if not t: continue
        t_l = t.lower(); sent = 'neutral'
        p_sc = sum(1 for w in pos if w in t_l); n_sc = sum(1 for w in neg if w in t_l)
        if p_sc > n_sc: sent = 'positive'
        elif n_sc > p_sc: sent = 'negative'
        analyzed.append({'title': t, 'link': n.get('link',''), 'sentiment': sent, 'publisher': n.get('publisher','News')})
    return analyzed

def process_news_for_list(stock_list):
    if not stock_list: return
    print(f"\nğŸ“° Top {len(stock_list)} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    for item in stock_list:
        ticker = item['id']; mkt = item['market']
        print(f"   [{mkt}] {ticker}...", end=' '); raw = []
        try:
            if mkt == 'KR': raw = get_news_from_google_kr(ticker)
            else: raw = get_news_from_google_us(ticker)
        except: pass
        print(f"{len(raw)}ê°œ"); item['news'] = analyze_news_sentiment(raw[:3])

def calculate_indicators(close, high, low):
    delta = close.diff(); gain = (delta.where(delta > 0, 0)).rolling(14).mean(); loss = (-delta.where(delta < 0, 0)).rolling(14).mean(); rs = gain/loss; rsi = 100 - (100/(1+rs))
    exp1 = close.ewm(span=12).mean(); exp2 = close.ewm(span=26).mean(); macd = exp1 - exp2; signal = macd.ewm(span=9).mean()
    ma20 = close.rolling(20).mean(); std = close.rolling(20).std(); upper = ma20 + (std*2); lower = ma20 - (std*2)
    lowest_low = low.rolling(window=14).min()
    highest_high = high.rolling(window=14).max()
    stoch_k = 100 * ((close - lowest_low) / (highest_high - lowest_low))
    stoch_d = stoch_k.rolling(window=3).mean()
    return rsi, macd, signal, upper, lower, ma20, stoch_k, stoch_d

def analyze_stock(ticker, market_type, target_date=None):
    try:
        stock = yf.Ticker(ticker)
        try: hist = stock.history(period="2y")
        except: return None
        if target_date:
            target_dt = datetime.strptime(target_date, "%Y-%m-%d")
            hist.index = hist.index.tz_localize(None)
            hist = hist[hist.index.strftime('%Y-%m-%d') <= target_date]
        if len(hist) < 120: return None
        
        info = {}
        try: info = stock.info 
        except: pass
        
        op_margin = info.get('operatingMargins')
        rev_growth = info.get('revenueGrowth')
        per = info.get('forwardPE') or info.get('trailingPE')
        pbr = info.get('priceToBook')

        if market_type == 'KR':
            kr_fund = get_kr_fundamental(ticker)
            if kr_fund:
                op_margin = kr_fund['op_margin']
                per = kr_fund['per']
                pbr = kr_fund['pbr']
        
        if market_type == 'KR' and op_margin is not None and op_margin < 0: return None
        if market_type == 'US' and op_margin is not None and op_margin < -0.5: return None
        
        close = hist['Close']; volume = hist['Volume']; high = hist['High']; low = hist['Low']
        rsi, macd, signal, bb_upper, bb_lower, ma20, stoch_k, stoch_d = calculate_indicators(close, high, low)
        
        cur_p = close.iloc[-1]; cur_rsi = rsi.iloc[-1]; cur_low = bb_lower.iloc[-1]
        ma60 = close.rolling(60).mean().iloc[-1]
        ma120 = close.rolling(120).mean().iloc[-1]
        cur_k = stoch_k.iloc[-1]
        vol_ma20 = volume.rolling(20).mean().iloc[-1]; cur_vol = volume.iloc[-1]
        rvol = safe_float(cur_vol / vol_ma20, 1.0) if vol_ma20 > 0 else 1.0
        
        sector = info.get('sector', 'ê¸°íƒ€')
        if market_type == 'KR' and sector == 'ê¸°íƒ€':
            if ticker in ['005930.KS', '000660.KS']: sector = 'Technology'
            elif ticker in ['005380.KS', '000270.KS']: sector = 'Automotive'
            
        if pd.isna(cur_rsi) or pd.isna(cur_p) or cur_rsi > 80: return None
        
        score = 0; reasons = [] 
        if cur_rsi < 30: score += 40; reasons.append("RSI ê³¼ë§¤ë„(ê°•ë ¥)")
        elif cur_rsi < 45: score += 20; reasons.append("ë‹¨ê¸° ê³¼ë§¤ë„")
        elif cur_rsi < 60: score += 5; reasons.append("ëˆŒë¦¼ëª© êµ¬ê°„")
        if cur_p <= cur_low * 1.05: score += 30; reasons.append("ë³¼ë¦°ì €ë°´ë“œ í•˜ë‹¨ ê·¼ì ‘")
        if not pd.isna(ma60) and cur_p >= ma60 * 0.98 and cur_p <= ma60 * 1.05: score += 20; reasons.append("60ì¼ì„  ì§€ì§€")
        if macd.iloc[-1] > signal.iloc[-1]: score += 15; reasons.append("MACD ìƒìŠ¹ì‹ í˜¸")
        if rvol >= 1.5: score += 20; reasons.append(f"ê±°ë˜ëŸ‰ í­ë°œ({rvol:.1f}ë°°)")
        elif rvol >= 1.2: score += 10; reasons.append(f"ê±°ë˜ëŸ‰ ì¦ê°€")
        if cur_k < 20: score += 15; reasons.append("ìŠ¤í† ìºìŠ¤í‹± ê³¼ë§¤ë„")
        if not pd.isna(ma120) and cur_p >= ma120: score += 10; reasons.append("ì¥ê¸° ìƒìŠ¹ ì¶”ì„¸")

        if market_type == 'US':
            if op_margin and op_margin > 0.15: score += 10; reasons.append("ì´ìµë¥  ìš°ìˆ˜")
            if rev_growth and rev_growth > 0.10: score += 10; reasons.append("ê³ ì„±ì¥ì£¼")
            if per and per > 0 and per < 30: score += 10; reasons.append("ì €í‰ê°€(PER)")
        elif market_type == 'KR':
            if per and per > 0 and per < 20: score += 5; reasons.append("ì ì • PER")
            if pbr and pbr > 0 and pbr < 1.5: score += 5; reasons.append("ì €PBR")
            if op_margin and op_margin > 0: score += 5; reasons.append("í‘ì ê¸°ì—…")
        
        cutoff = 40 
        if score < cutoff: return None
        
        name = info.get('shortName', ticker) if info else ticker
        price_val = safe_float(round(cur_p, 2))
        
        hist_data = []
        for d, r in hist.iloc[-20:].iterrows():
            p = round(float(r['Close']), 2) if not math.isnan(r['Close']) else None
            b_u = round(float(bb_upper.loc[d]), 2) if not math.isnan(bb_upper.loc[d]) else None
            b_l = round(float(bb_lower.loc[d]), 2) if not math.isnan(bb_lower.loc[d]) else None
            hist_data.append({"time": d.strftime("%m-%d"), "price": p, "bb_upper": b_u, "bb_lower": b_l})

        return {
            "id": ticker, "rank": 0, "symbol": ticker.replace('.KS','').replace('.KQ',''), "name": name, "market": market_type,
            "currentPrice": price_val,
            "changePercent": safe_float(round(((cur_p - hist['Close'].iloc[-2]) / hist['Close'].iloc[-2]) * 100, 2)),
            "buyZoneTop": safe_float(round(cur_p * 1.02, 2), price_val), "buyZoneBottom": safe_float(round(cur_p * 0.98, 2), price_val),
            "targetPrice": safe_float(round(cur_p * 1.1, 2), price_val), "aiReason": " + ".join(reasons),
            "score": int(score), "rsi": safe_float(round(cur_rsi, 2)), "history": hist_data, "news": [],
            "financials": { "op_margin": safe_float(op_margin), "rev_growth": safe_float(rev_growth), "per": safe_float(per) },
            "sector": sector, "rvol": safe_float(round(rvol, 2))
        }
    except: return None

def generate_weekly_report(target_date_str):
    print(f"\nğŸ“Š [Weekly] {target_date_str} ê¸°ì¤€ ì£¼ê°„ ì„±ê³¼ ë¶„ì„ ì‹œì‘...")
    daily_files = []
    end_date = datetime.strptime(target_date_str, "%Y-%m-%d")
    start_date = end_date - timedelta(days=14)
    
    if not os.path.exists(DAILY_DATA_DIR): os.makedirs(DAILY_DATA_DIR)
    if not os.path.exists(WEEKLY_REPORT_DIR): os.makedirs(WEEKLY_REPORT_DIR)

    for f in os.listdir(DAILY_DATA_DIR):
        if f.endswith('_daily.json'):
            try:
                file_date = datetime.strptime(f.split('_')[0], "%Y-%m-%d")
                if start_date <= file_date <= end_date: daily_files.append(f)
            except: pass
            
    print(f"ğŸ“‚ ë¶„ì„ ëŒ€ìƒ ë°ì¼ë¦¬ íŒŒì¼: {len(daily_files)}ê°œ")
    
    aggregated_stocks = []
    for file in daily_files:
        with open(f"{DAILY_DATA_DIR}/{file}", 'r', encoding='utf-8') as f:
            data = json.load(f)
            rec_date = file.split('_')[0]
            for stock in data.get('stocks', []):
                stock['buyPrice'] = stock['currentPrice'] 
                stock['recommendDate'] = rec_date
                aggregated_stocks.append(stock)

    print(f"ğŸ” ì´ {len(aggregated_stocks)}ê°œì˜ ê³¼ê±° ì¶”ì²œ ë‚´ì—­ ìˆ˜ìµë¥  ê³„ì‚° ì¤‘...")

    final_results = []
    for i, item in enumerate(aggregated_stocks):
        if i % 10 == 0: time.sleep(1)
        ticker = item['id']
        buy_price = item['buyPrice']
        try:
            stock_info = yf.Ticker(ticker)
            target_dt = datetime.strptime(target_date_str, "%Y-%m-%d")
            hist = stock_info.history(period="6mo")
            if hist.empty: continue
            hist.index = hist.index.tz_localize(None)
            hist_until_target = hist[hist.index.strftime('%Y-%m-%d') <= target_date_str]
            
            if not hist_until_target.empty:
                current_price = float(hist_until_target['Close'].iloc[-1])
                return_rate = ((current_price - buy_price) / buy_price) * 100
                new_item = item.copy()
                new_item['currentPrice'] = round(current_price, 2)
                new_item['returnRate'] = round(return_rate, 2)
                final_results.append(new_item)
        except: pass 

    us_results = [s for s in final_results if s['market'] == 'US']
    kr_results = [s for s in final_results if s['market'] == 'KR']
    us_results.sort(key=lambda x: x['returnRate'], reverse=True)
    kr_results.sort(key=lambda x: x['returnRate'], reverse=True)
    
    top_performers = us_results[:10] + kr_results[:10]
    for i, item in enumerate(top_performers): item['rank'] = (i % 10) + 1
        
    ms = analyze_market_condition(target_date=target_date_str)
    out = {
        "market_status": ms, "stocks": top_performers, "dominant_sectors": [], 
        "timestamp": f"{target_date_str} 08:00:00 (Weekly Report)"
    }
    
    output_path = f"{WEEKLY_REPORT_DIR}/{target_date_str}_weekly.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(out, f, indent=2, ensure_ascii=False, allow_nan=False)
    print(f"\nâœ… ì£¼ê°„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}")

def send_weekly_summary_notification():
    print(f"\nğŸ“¢ [Weekly Summary] ì£¼ê°„ ìˆ˜ìµë¥  ê²°ì‚° ì•Œë¦¼ ì „ì†¡ ì‹œì‘...")
    today_str = (datetime.utcnow() + timedelta(hours=9)).strftime("%Y-%m-%d") # í•œêµ­ ì‹œê°„ ê¸°ì¤€
    report_file_path = f"{WEEKLY_REPORT_DIR}/{today_str}_weekly.json"
    
    if not os.path.exists(report_file_path):
        print(f"âš ï¸ ì˜¤ëŠ˜ì({today_str}) ë¦¬í¬íŠ¸ê°€ ì—†ì–´ì„œ ìë™ ìƒì„±í•©ë‹ˆë‹¤...")
        generate_weekly_report(today_str)
        update_history_index()

    title = "ğŸ“Š ì£¼ê°„ ìˆ˜ìµë¥  ê²°ì‚° ë„ì°©"
    body = "ì§€ë‚œ 2ì£¼ê°„ì˜ ì¶”ì²œ ì¢…ëª© ì„±ê³¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆ ì•±ì—ì„œ í•œêµ­/ë¯¸êµ­ Top 10 ìˆ˜ìµë¥ ì„ í™•ì¸í•´ë³´ì„¸ìš”!"
    send_push_notification(title, body)

def update_history_index():
    if not os.path.exists(WEEKLY_REPORT_DIR): return
    hl = []
    for f in sorted(os.listdir(WEEKLY_REPORT_DIR), reverse=True):
        if f.endswith('_weekly.json'): 
            d_str = f.split('_')[0]
            hl.append({"date": d_str, "file": f"{WEEKLY_REPORT_DIR}/{f}"})
    with open('history_index.json', 'w', encoding='utf-8') as f: json.dump(hl, f, indent=2, ensure_ascii=False)

def run_backfill(start_date, end_date):
    print(f"\nâª Backfill Mode: {start_date} ~ {end_date}")
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    if not os.path.exists(DAILY_DATA_DIR): os.makedirs(DAILY_DATA_DIR)

    print("ğŸ“‹ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë¡œë”© ì¤‘...")
    sp500 = get_sp500_tickers()
    nasdaq100 = get_nasdaq100_tickers()
    us_tickers = list(set(sp500 + nasdaq100))
    kr_tickers = get_korea_tickers()
    
    current_dt = start_dt
    while current_dt <= end_dt:
        if current_dt.weekday() >= 5: 
            current_dt += timedelta(days=1)
            continue
        target_str = current_dt.strftime("%Y-%m-%d")
        print(f"\nğŸ“… [Backfill] ì²˜ë¦¬ ì¤‘: {target_str}")
        
        ms = analyze_market_condition(target_date=target_str)
        final_stocks = []
        
        print(f"ğŸ‡ºğŸ‡¸ US Analyzing...")
        usc = []
        for i, t in enumerate(us_tickers):
            d = analyze_stock(t, 'US', target_date=target_str)
            if d: usc.append(d)
        usc.sort(key=lambda x: x['score'], reverse=True)
        final_stocks.extend(usc[:10])
        
        print(f"ğŸ‡°ğŸ‡· KR Analyzing...")
        krc = []
        for i, t in enumerate(kr_tickers):
            d = analyze_stock(t, 'KR', target_date=target_str)
            if d: krc.append(d)
        krc.sort(key=lambda x: x['score'], reverse=True)
        final_stocks.extend(krc[:10])
        
        for i, item in enumerate(final_stocks): 
            if item['market']=='US': item['rank'] = (i % 10) + 1
            else: item['rank'] = (i % 10) + 1 # ìˆœìœ„ ì¬ì¡°ì • ë¡œì§ í•„ìš”ì‹œ ìˆ˜ì •

        all_sectors = [s['sector'] for s in final_stocks if s['sector'] != 'ê¸°íƒ€']
        dominant_sectors = [item[0] for item in Counter(all_sectors).most_common(2)]

        out = {
            "market_status": ms, "stocks": final_stocks, "dominant_sectors": dominant_sectors, 
            "timestamp": f"{target_str} 16:00:00", 
            "notification": { "title": "", "body": "" }
        }
        
        filename = f"{DAILY_DATA_DIR}/{target_str}_daily.json"
        with open(filename, 'w', encoding='utf-8') as f: json.dump(out, f, indent=2, ensure_ascii=False, allow_nan=False)
        print(f"ğŸ’¾ Saved: {filename}")
        current_dt += timedelta(days=1)

    print("\nâœ… Backfill Complete!")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', type=str, default='daily', help='daily, weekly, weekly_summary, backfill, update_index, test_push')
    parser.add_argument('--target', type=str, default='ALL', help='US, KR, ALL')
    parser.add_argument('--date', type=str, default=None)
    parser.add_argument('--start', type=str, default=None)
    parser.add_argument('--end', type=str, default=None)
    args = parser.parse_args()
    
    # [ìˆ˜ì •] í•œêµ­ ì‹œê°„ ê¸°ì¤€ ì˜¤ëŠ˜ ë‚ ì§œ ê³„ì‚° (ì„œë²„ ì‹œê°„ ì˜¤ì°¨ ë°©ì§€)
    if args.date:
        today_str = args.date
    else:
        today_str = (datetime.utcnow() + timedelta(hours=9)).strftime("%Y-%m-%d")
        
    print(f"ğŸš€ AI ì£¼ì‹ ë¶„ì„ê¸° ê°€ë™ (ëª¨ë“œ: {args.mode}, íƒ€ê²Ÿ: {args.target}, ë‚ ì§œ: {today_str})")

    if args.mode == 'daily':
        if not os.path.exists(DAILY_DATA_DIR): os.makedirs(DAILY_DATA_DIR)
        prev_stock_ids = get_latest_recommendation_ids()
        
        # ê¸°ì¡´ íŒŒì¼ ë¡œë“œ (ëˆ„ì  ì—…ë°ì´íŠ¸ìš©)
        existing_stocks = []
        try:
            with open('todays_recommendation.json', 'r', encoding='utf-8') as f:
                existing_stocks = json.load(f).get('stocks', [])
        except: pass

        ms = analyze_market_condition(target_date=today_str)
        final_stocks = []
        
        # US ì²˜ë¦¬
        if args.target in ['US', 'ALL']:
            sp500 = get_sp500_tickers(); nasdaq100 = get_nasdaq100_tickers()
            us_tickers = list(set(sp500 + nasdaq100))
            print(f"\nğŸ‡ºğŸ‡¸ ë¯¸êµ­ ë¶„ì„ (ëŒ€ìƒ: {len(us_tickers)}ê°œ)...")
            usc = []
            for i, t in enumerate(us_tickers): 
                # print(f"[{i+1}/{len(us_tickers)}] {t}...", end='\r'); 
                d = analyze_stock(t, 'US', target_date=today_str)
                if d: usc.append(d)
            usc.sort(key=lambda x: x['score'], reverse=True); ust = usc[:10]
            for i, item in enumerate(ust): item['rank'] = i + 1
            process_news_for_list(ust)
            final_stocks.extend(ust)
        else:
            us_kept = [s for s in existing_stocks if s['market'] == 'US']
            final_stocks.extend(us_kept)

        # KR ì²˜ë¦¬
        if args.target in ['KR', 'ALL']:
            kr = get_korea_tickers(); krc = []
            print(f"\nğŸ‡°ğŸ‡· í•œêµ­ ë¶„ì„ (ëŒ€ìƒ: {len(kr)}ê°œ)...")
            for i, t in enumerate(kr): 
                # print(f"[{i+1}/{len(kr)}] {t}...", end='\r'); 
                d = analyze_stock(t, 'KR', target_date=today_str)
                if d: krc.append(d)
            krc.sort(key=lambda x: x['score'], reverse=True); krt = krc[:10]
            for i, item in enumerate(krt): item['rank'] = i + 1
            process_news_for_list(krt)
            final_stocks.extend(krt)
        else:
            kr_kept = [s for s in existing_stocks if s['market'] == 'KR']
            final_stocks.extend(kr_kept)
        
        # ì €ì¥ ë° ì•Œë¦¼
        all_sectors = [s['sector'] for s in final_stocks if s['sector'] != 'ê¸°íƒ€']
        dominant_sectors = [item[0] for item in Counter(all_sectors).most_common(2)]
        
        noti_title = "ğŸ”” DailyPick10 ì•Œë¦¼"
        noti_body = ""
        
        target_market_stocks = [s for s in final_stocks if s['market'] == args.target] if args.target != 'ALL' else final_stocks
        
        if target_market_stocks:
            new_stocks = [s['symbol'] for s in target_market_stocks if s['id'] not in prev_stock_ids]
            market_name = "ë¯¸êµ­" if args.target == 'US' else ("í•œêµ­" if args.target == 'KR' else "ì „ì²´")
            if new_stocks:
                highlight = ", ".join(new_stocks[:2])
                noti_body = f"ì˜¤ëŠ˜ì˜ {market_name} ì¶”ì²œ: {highlight} ë“± (ì‹ ê·œ {len(new_stocks)}ê±´)"
            else:
                top = ", ".join([s['symbol'] for s in target_market_stocks[:2]])
                noti_body = f"ì˜¤ëŠ˜ì˜ {market_name} ì¶”ì²œ: {top} ë“± (ìˆœìœ„ ë³€ë™)"

        out = {
            "market_status": ms, "stocks": final_stocks, "dominant_sectors": dominant_sectors, 
            "timestamp": f"{today_str} {datetime.now().strftime('%H:%M:%S')}",
            "notification": { "title": noti_title, "body": noti_body }
        }
        
        with open('todays_recommendation.json', 'w', encoding='utf-8') as f: json.dump(out, f, indent=2, ensure_ascii=False, allow_nan=False)
        with open(f"{DAILY_DATA_DIR}/{today_str}_daily.json", 'w', encoding='utf-8') as f: json.dump(out, f, indent=2, ensure_ascii=False, allow_nan=False)

        if noti_body and args.date is None:
            send_push_notification(noti_title, noti_body)
    
    elif args.mode == 'weekly':
        generate_weekly_report(today_str)
        update_history_index()
    
    elif args.mode == 'weekly_summary':
        send_weekly_summary_notification()
    
    elif args.mode == 'backfill':
        if args.start and args.end: run_backfill(args.start, args.end)
    
    elif args.mode == 'update_index':
        update_history_index()

    elif args.mode == 'test_push':
        send_push_notification("ğŸ”” í…ŒìŠ¤íŠ¸ ì•Œë¦¼", "ì´ê²ƒì€ ê°•ì œ ì „ì†¡ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤!")

    print(f"\nâœ… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__": main()