import yfinance as yf
import pandas as pd
import json
import time
import ssl
import requests
import xml.etree.ElementTree as ET
import math
import os
import sys
import re
import argparse 
from collections import Counter
from datetime import datetime, timedelta

# SSL ì¸ì¦ì„œ ì˜¤ë¥˜ ë°©ì§€
ssl._create_default_https_context = ssl._create_unverified_context

# í´ë” ê²½ë¡œ ìƒìˆ˜ ì •ì˜
DAILY_DATA_DIR = 'daily_data'
WEEKLY_REPORT_DIR = 'weekly_reports'

# --- [ì•ˆì „ì¥ì¹˜] ---
def safe_float(val, default=0.0):
    try:
        if val is None or val == "" or str(val).strip() == "-": return default
        f = float(val)
        if math.isnan(f) or math.isinf(f): return default
        return f
    except: return default

# --- [Git ê°•ì œ ì—…ë¡œë“œ í•¨ìˆ˜ (ìˆ˜ì •ë¨: ì•ˆì •ì„± ê°•í™”)] ---
def git_push_updates(mode_name):
    """
    ë°ì´í„°ê°€ ìƒì„±ë˜ìë§ˆì ì•Œë¦¼ë³´ë‹¤ ë¨¼ì € ì„œë²„ì— ë°˜ì˜ë˜ë„ë¡ ê°•ì œë¡œ Pushí•©ë‹ˆë‹¤.
    (Pull -> Commit -> Push ìˆœì„œë¡œ ì¶©ëŒ ë°©ì§€)
    """
    try:
        print(f"\nâ¬†ï¸ [Git] ë°ì´í„° ê°•ì œ ì—…ë¡œë“œ ì‹œë„ ({mode_name})...")
        
        # Git ì‚¬ìš©ì ì„¤ì • (ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆì–´ë„ ì•ˆì „í•¨)
        os.system("git config --global user.name 'GitHub Action'")
        os.system("git config --global user.email 'action@github.com'")
        
        # ìµœì‹  ìƒíƒœ ê°€ì ¸ì˜¤ê¸° (ì¶©ëŒ ë°©ì§€)
        print("  - Pulling latest changes...")
        os.system("git pull --rebase origin master || git pull --rebase origin main")
        
        # íŒŒì¼ ìŠ¤í…Œì´ì§•
        os.system("git add todays_recommendation.json")
        os.system(f"git add {DAILY_DATA_DIR}/*.json")
        os.system(f"git add {WEEKLY_REPORT_DIR}/*.json")
        os.system("git add history_index.json")
        
        # ì»¤ë°‹
        commit_msg = f"Auto-update stock data ({mode_name}) - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        os.system(f"git commit -m '{commit_msg}' || echo 'No changes to commit'")
        
        # í‘¸ì‹œ (master ë¸Œëœì¹˜ë¡œ ì‹œë„, ì‹¤íŒ¨ ì‹œ mainìœ¼ë¡œ ì‹œë„)
        print("  - Pushing to remote...")
        push_result = os.system("git push origin master || git push origin main")
        
        if push_result == 0:
            print("âœ… [Git] ì—…ë¡œë“œ ì„±ê³µ!")
            # GitHub Pages ë°˜ì˜ ëŒ€ê¸° (90ì´ˆ)
            print("â³ ì„œë²„ ë°˜ì˜ ëŒ€ê¸° ì¤‘ (90ì´ˆ)... ì•Œë¦¼ì€ ì ì‹œ í›„ì— ë°œì†¡ë©ë‹ˆë‹¤.")
            time.sleep(90) 
        else:
            print("âŒ [Git] ì—…ë¡œë“œ ì‹¤íŒ¨ (Push Error)")
            
    except Exception as e:
        print(f"âŒ [Git] ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

# --- [ì•Œë¦¼ ì „ì†¡ í•¨ìˆ˜] ---
def send_push_notification(title, message):
    user_push_tokens = ["ExponentPushToken[hiUjiJITCNaVruAohWwGtG]"] 

    if not user_push_tokens:
        print(f"âš ï¸ [ì•Œë¦¼] ì „ì†¡í•  í† í°ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    url = "https://exp.host/--/api/v2/push/send"
    headers = {
        "host": "exp.host",
        "accept": "application/json",
        "accept-encoding": "gzip, deflate",
        "content-type": "application/json"
    }

    print(f"ğŸ“¨ ì•Œë¦¼ ì „ì†¡ ì‹œì‘: '{title}' (ëŒ€ìƒ: {len(user_push_tokens)}ëª…)")
    
    for token in user_push_tokens:
        if not token.startswith("ExponentPushToken"):
            print(f"  âŒ ì˜ëª»ëœ í† í° í˜•ì‹ ê±´ë„ˆëœ€: {token}")
            continue
            
        payload = {
            "to": token,
            "title": title,
            "body": message,
            "sound": "default",
            "priority": "high",
            "channelId": "default", 
            "badge": 1,
            "_displayInForeground": True
        }

        try:
            response = requests.post(url, headers=headers, data=json.dumps(payload))
            if response.status_code == 200:
                res_json = response.json()
                if res_json.get('data', {}).get('status') == 'ok':
                    print(f"  âœ… ì „ì†¡ ì„±ê³µ ({token})")
                else:
                    print(f"  âŒ ì „ì†¡ ì˜¤ë¥˜ ({token}): {res_json}")
            else:
                print(f"  âŒ ì„œë²„ í†µì‹  ì‹¤íŒ¨ ({response.status_code}): {response.text}")
        except Exception as e:
            print(f"  âŒ ì „ì†¡ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

# --- [ì–´ì œ ì¶”ì²œ ì¢…ëª© ê°€ì ¸ì˜¤ê¸°] ---
def get_latest_recommendation_ids():
    if not os.path.exists(DAILY_DATA_DIR): return set()
    files = sorted([f for f in os.listdir(DAILY_DATA_DIR) if f.endswith('_daily.json')], reverse=True)
    if not files: return set()
    try:
        with open(f"{DAILY_DATA_DIR}/{files[0]}", 'r', encoding='utf-8') as f:
            data = json.load(f)
            return {s['id'] for s in data.get('stocks', [])}
    except:
        return set()

# --- [ì–´ì œ ì¶”ì²œ ì¢…ëª© ê°€ì ¸ì˜¤ê¸° (ë‚ ì§œ ê¸°ì¤€, ë°±í•„ìš©)] ---
def get_previous_recommendation_ids(target_date_str):
    if not os.path.exists(DAILY_DATA_DIR): return set()
    
    target_date = datetime.strptime(target_date_str, "%Y-%m-%d")
    files = sorted([f for f in os.listdir(DAILY_DATA_DIR) if f.endswith('_daily.json')], reverse=True)
    
    for f in files:
        file_date_str = f.split('_')[0]
        try:
            file_date = datetime.strptime(file_date_str, "%Y-%m-%d")
            if file_date < target_date:
                with open(f"{DAILY_DATA_DIR}/{f}", 'r', encoding='utf-8') as file:
                    data = json.load(file)
                    return {s['id'] for s in data.get('stocks', [])}
        except:
            continue
    return set()

# --- [1] ì‹œì¥ ìƒí™© ë¶„ì„ ---
def analyze_market_condition(target_date=None):
    print("ğŸŒ ê¸€ë¡œë²Œ ì‹œì¥ ìƒí™© ë¶„ì„ ì¤‘...")
    markets = {'US': {'ticker': '^GSPC', 'name': 'S&P 500'}, 'KR': {'ticker': '^KS11', 'name': 'KOSPI'}, 'VIX': {'ticker': '^VIX', 'name': 'ê³µí¬ì§€ìˆ˜'}}
    market_status = {}
    for key, info in markets.items():
        try:
            ticker = yf.Ticker(info['ticker'])
            hist = ticker.history(period="2y") 
            
            if target_date:
                hist.index = hist.index.tz_localize(None) 
                hist = hist[hist.index.strftime('%Y-%m-%d') <= target_date]

            if len(hist) < 2:
                market_status[key] = {'status': 'UNKNOWN', 'change': 0.0, 'current': 0.0, 'message': 'ë°ì´í„° ì—†ìŒ'}
                continue
                
            current = hist['Close'].iloc[-1]; prev = hist['Close'].iloc[-2]
            change_pct = ((current - prev) / prev) * 100
            status, message = "NEUTRAL", ""
            
            if key == 'VIX':
                if current >= 30: status, message = "PANIC", "ê·¹ë„ì˜ ê³µí¬ ğŸ˜±"
                elif current >= 20: status, message = "BAD", "ê³µí¬ êµ¬ê°„ ğŸ˜¨"
                elif current <= 15: status, message = "VERY_GOOD", "ì‹œì¥ ê³¼ì—´ ğŸ¤‘"
                else: status, message = "NEUTRAL", "ì•ˆì •ì  ğŸ˜Œ"
            else:
                if change_pct >= 1.0: status, message = "VERY_GOOD", "ê°•í•œ ìƒìŠ¹ ğŸ”¥"
                elif change_pct >= 0.2: status, message = "GOOD", "ìƒìŠ¹ì„¸ ğŸ“ˆ"
                elif change_pct > -0.5: status, message = "NEUTRAL", "ë³´í•©ì„¸ â–"
                elif change_pct > -1.5: status, message = "BAD", "í•˜ë½ì„¸ â˜ï¸"
                else: status, message = "PANIC", "í­ë½ ê²½ê³  â›ˆï¸"
                
            market_status[key] = {'name': info['name'], 'current': safe_float(round(current, 2)), 'change': safe_float(round(change_pct, 2)), 'status': status, 'message': message}
        except Exception as e: 
            print(f"âš ï¸ {key} ì§€ìˆ˜ ë¶„ì„ ì‹¤íŒ¨: {e}")
            market_status[key] = {'status': 'UNKNOWN', 'change': 0.0, 'message': 'ë¶„ì„ ì‹¤íŒ¨'}
    return market_status

# --- [2] ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ---
def get_sp500_tickers():
    try:
        url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers)
        table = pd.read_html(response.text)
        tickers = table[0]['Symbol'].tolist()
        return [t.replace('.', '-') for t in tickers]
    except: return ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'NVDA', 'TSLA', 'META']

def get_nasdaq100_tickers():
    try:
        url = 'https://en.wikipedia.org/wiki/Nasdaq-100'
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers)
        tables = pd.read_html(response.text)
        for table in tables:
            if 'Ticker' in table.columns:
                return [str(t).replace('.', '-') for t in table['Ticker'].tolist()]
            elif 'Symbol' in table.columns:
                return [str(t).replace('.', '-') for t in table['Symbol'].tolist()]
        return []
    except Exception as e:
        print(f"âš ï¸ ë‚˜ìŠ¤ë‹¥ 100 ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return []

def get_korea_tickers():
    tickers = []
    try:
        url = 'https://finance.naver.com/sise/sise_market_sum.naver?sosok=0&page=1'
        res = requests.get(url)
        codes = re.findall(r'href="/item/main.naver\?code=(\d{6})"', res.text)
        seen = set()
        unique_codes = [x for x in codes if not (x in seen or seen.add(x))]
        for code in unique_codes[:50]: tickers.append(f"{code}.KS")
    except Exception as e: print(f"âš ï¸ ì½”ìŠ¤í”¼ ëª©ë¡ ì‹¤íŒ¨: {e}")

    try:
        url = 'https://finance.naver.com/sise/sise_market_sum.naver?sosok=1&page=1'
        res = requests.get(url)
        codes = re.findall(r'href="/item/main.naver\?code=(\d{6})"', res.text)
        seen = set()
        unique_codes = [x for x in codes if not (x in seen or seen.add(x))]
        for code in unique_codes[:50]: tickers.append(f"{code}.KQ")
    except Exception as e: print(f"âš ï¸ ì½”ìŠ¤ë‹¥ ëª©ë¡ ì‹¤íŒ¨: {e}")

    if not tickers:
        return ['005930.KS', '000660.KS', '373220.KS', '005380.KS', '000270.KS', '068270.KS', '005490.KS', '035420.KS']
    return tickers

# --- [ì‹ ê·œ] ë„¤ì´ë²„ ê¸ˆìœµ ì¬ë¬´ ë°ì´í„° í¬ë¡¤ë§ ---
def get_kr_fundamental(ticker):
    """ë„¤ì´ë²„ ê¸ˆìœµì—ì„œ PER, PBR, ì˜ì—…ì´ìµë¥  ë“±ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤."""
    try:
        code = ticker.split('.')[0] # 005930.KS -> 005930
        url = f"https://finance.naver.com/item/main.naver?code={code}"
        
        # ë„¤ì´ë²„ ê¸ˆìœµì€ EUC-KR ì‚¬ìš©
        dfs = pd.read_html(url, encoding='euc-kr')
        
        # 'ê¸°ì—…ì‹¤ì ë¶„ì„' í…Œì´ë¸” ì°¾ê¸°
        fin_df = None
        for df in dfs:
            if df.shape[1] > 1 and 'ì˜ì—…ì´ìµë¥ ' in str(df.iloc[:, 0].values):
                fin_df = df
                break
        
        if fin_df is None: return None

        fin_df.set_index(fin_df.columns[0], inplace=True)
        target_col = fin_df.columns[-1] 

        def get_val(row_name):
            try:
                rows = fin_df[fin_df.index.str.contains(row_name, na=False)]
                if len(rows) > 0:
                    val = rows.iloc[0][target_col]
                    return safe_float(val, None) 
                return None
            except: return None

        op_margin = get_val('ì˜ì—…ì´ìµë¥ ')
        per = get_val('PER')
        pbr = get_val('PBR')
        
        return {
            "op_margin": op_margin / 100.0 if op_margin else None, 
            "per": per,
            "pbr": pbr,
            "rev_growth": None 
        }

    except Exception as e:
        return None

# --- [3] ë‰´ìŠ¤ ìˆ˜ì§‘ ---
def get_news_from_google_kr(ticker):
    try:
        url = f"https://news.google.com/rss/search?q={ticker.split('.')[0]}+ì£¼ê°€&hl=ko&gl=KR&ceid=KR:ko"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=3); root = ET.fromstring(response.content)
        return [{'title': item.find('title').text, 'link': item.find('link').text, 'publisher': item.find('source').text} for item in root.findall('./channel/item')[:3]]
    except: return []

def get_news_from_google_us(ticker):
    try:
        url = f"https://news.google.com/rss/search?q={ticker}+stock&hl=en-US&gl=US&ceid=US:en"
        headers = {"User-Agent": "Mozilla/5.0"}
        response = requests.get(url, headers=headers, timeout=3); root = ET.fromstring(response.content)
        return [{'title': item.find('title').text, 'link': item.find('link').text, 'publisher': item.find('source').text} for item in root.findall('./channel/item')[:3]]
    except: return []

def analyze_news_sentiment(news_list):
    analyzed = []
    pos = ['surge', 'jump', 'soar', 'gain', 'profit', 'buy', 'growth', 'record', 'upgrade', 'ê¸‰ë“±', 'ìƒìŠ¹', 'í˜¸ì¬', 'ì¦ê°€', 'ê°œì„ ', 'ë§¤ìˆ˜', 'ì²´ê²°', 'ì„±ì¥', 'ìµœê³ ']
    neg = ['drop', 'fall', 'plunge', 'loss', 'miss', 'sell', 'crash', 'downgrade', 'lawsuit', 'ê¸‰ë½', 'í•˜ë½', 'ì•…ì¬', 'ê°ì†Œ', 'ë¶€ì§„', 'ë§¤ë„', 'ì ì', 'ìš°ë ¤', 'ì†Œì†¡']
    for n in news_list:
        t = n.get('title', '').strip(); 
        if not t: continue
        t_l = t.lower(); sent = 'neutral'
        p_sc = sum(1 for w in pos if w in t_l); n_sc = sum(1 for w in neg if w in t_l)
        if p_sc > n_sc: sent = 'positive'
        elif n_sc > p_sc: sent = 'negative'
        analyzed.append({'title': t, 'link': n.get('link',''), 'sentiment': sent, 'publisher': n.get('publisher','News')})
    return analyzed

def process_news_for_list(stock_list):
    if not stock_list: return
    print(f"\nğŸ“° Top {len(stock_list)} ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
    for item in stock_list:
        ticker = item['id']; mkt = item['market']
        print(f"   [{mkt}] {ticker}...", end=' '); raw = []
        try:
            if mkt == 'KR': raw = get_news_from_google_kr(ticker)
            else: raw = get_news_from_google_us(ticker)
        except: pass
        print(f"{len(raw)}ê°œ"); item['news'] = analyze_news_sentiment(raw[:3])

# --- [4] ì§€í‘œ ê³„ì‚° ---
def calculate_indicators(close, high, low):
    delta = close.diff(); gain = (delta.where(delta > 0, 0)).rolling(14).mean(); loss = (-delta.where(delta < 0, 0)).rolling(14).mean(); rs = gain/loss; rsi = 100 - (100/(1+rs))
    exp1 = close.ewm(span=12).mean(); exp2 = close.ewm(span=26).mean(); macd = exp1 - exp2; signal = macd.ewm(span=9).mean()
    ma20 = close.rolling(20).mean(); std = close.rolling(20).std(); upper = ma20 + (std*2); lower = ma20 - (std*2)
    lowest_low = low.rolling(window=14).min()
    highest_high = high.rolling(window=14).max()
    stoch_k = 100 * ((close - lowest_low) / (highest_high - lowest_low))
    stoch_d = stoch_k.rolling(window=3).mean()
    return rsi, macd, signal, upper, lower, ma20, stoch_k, stoch_d

# --- [5] ê°œë³„ ì¢…ëª© ë¶„ì„ ---
def analyze_stock(ticker, market_type, target_date=None):
    try:
        stock = yf.Ticker(ticker)
        try: hist = stock.history(period="2y")
        except: return None
        
        if target_date:
            target_dt = datetime.strptime(target_date, "%Y-%m-%d")
            hist.index = hist.index.tz_localize(None)
            hist = hist[hist.index.strftime('%Y-%m-%d') <= target_date]

        if len(hist) < 120: return None
        
        info = {}
        try: info = stock.info 
        except: pass
        
        op_margin = info.get('operatingMargins')
        rev_growth = info.get('revenueGrowth')
        per = info.get('forwardPE') or info.get('trailingPE')
        pbr = info.get('priceToBook')

        if market_type == 'KR':
            kr_fund = get_kr_fundamental(ticker)
            if kr_fund:
                op_margin = kr_fund['op_margin']
                per = kr_fund['per']
                pbr = kr_fund['pbr']
        
        # í•„í„°ë§
        if market_type == 'KR' and op_margin is not None and op_margin < 0: return None
        if market_type == 'US' and op_margin is not None and op_margin < -0.5: return None
        
        close = hist['Close']; volume = hist['Volume']; high = hist['High']; low = hist['Low']
        rsi, macd, signal, bb_upper, bb_lower, ma20, stoch_k, stoch_d = calculate_indicators(close, high, low)
        
        cur_p = close.iloc[-1]; cur_rsi = rsi.iloc[-1]; cur_low = bb_lower.iloc[-1]
        ma60 = close.rolling(60).mean().iloc[-1]
        ma120 = close.rolling(120).mean().iloc[-1]
        cur_k = stoch_k.iloc[-1]
        vol_ma20 = volume.rolling(20).mean().iloc[-1]; cur_vol = volume.iloc[-1]
        rvol = safe_float(cur_vol / vol_ma20, 1.0) if vol_ma20 > 0 else 1.0
        
        sector = info.get('sector', 'ê¸°íƒ€')
        if market_type == 'KR' and sector == 'ê¸°íƒ€':
            if ticker in ['005930.KS', '000660.KS']: sector = 'Technology'
            elif ticker in ['005380.KS', '000270.KS']: sector = 'Automotive'
            
        if pd.isna(cur_rsi) or pd.isna(cur_p) or cur_rsi > 80: return None
        
        score = 0; reasons = [] 
        
        # Technical Score
        if cur_rsi < 30: score += 40; reasons.append("RSI ê³¼ë§¤ë„(ê°•ë ¥)")
        elif cur_rsi < 45: score += 20; reasons.append("ë‹¨ê¸° ê³¼ë§¤ë„")
        elif cur_rsi < 60: score += 5; reasons.append("ëˆŒë¦¼ëª© êµ¬ê°„")
        
        if cur_p <= cur_low * 1.05: score += 30; reasons.append("ë³¼ë¦°ì €ë°´ë“œ í•˜ë‹¨ ê·¼ì ‘")
        if not pd.isna(ma60) and cur_p >= ma60 * 0.98 and cur_p <= ma60 * 1.05: score += 20; reasons.append("60ì¼ì„  ì§€ì§€")
        if macd.iloc[-1] > signal.iloc[-1]: score += 15; reasons.append("MACD ìƒìŠ¹ì‹ í˜¸")
        if rvol >= 1.5: score += 20; reasons.append(f"ê±°ë˜ëŸ‰ í­ë°œ({rvol:.1f}ë°°)")
        elif rvol >= 1.2: score += 10; reasons.append(f"ê±°ë˜ëŸ‰ ì¦ê°€")
        if cur_k < 20: score += 15; reasons.append("ìŠ¤í† ìºìŠ¤í‹± ê³¼ë§¤ë„")
        if not pd.isna(ma120) and cur_p >= ma120: score += 10; reasons.append("ì¥ê¸° ìƒìŠ¹ ì¶”ì„¸")

        # Fundamental Score
        if market_type == 'US':
            if op_margin and op_margin > 0.15: score += 10; reasons.append("ì´ìµë¥  ìš°ìˆ˜")
            if rev_growth and rev_growth > 0.10: score += 10; reasons.append("ê³ ì„±ì¥ì£¼")
            if per and per > 0 and per < 30: score += 10; reasons.append("ì €í‰ê°€(PER)")
        elif market_type == 'KR':
            if per and per > 0 and per < 20: score += 5; reasons.append("ì ì • PER")
            if pbr and pbr > 0 and pbr < 1.5: score += 5; reasons.append("ì €PBR")
            if op_margin and op_margin > 0: score += 5; reasons.append("í‘ì ê¸°ì—…")
        
        cutoff = 40 
        if score < cutoff: return None
        
        name = info.get('shortName', ticker) if info else ticker
        price_val = safe_float(round(cur_p, 2))
        
        hist_data = []
        for d, r in hist.iloc[-20:].iterrows():
            p = round(float(r['Close']), 2) if not math.isnan(r['Close']) else None
            b_u = round(float(bb_upper.loc[d]), 2) if not math.isnan(bb_upper.loc[d]) else None
            b_l = round(float(bb_lower.loc[d]), 2) if not math.isnan(bb_lower.loc[d]) else None
            hist_data.append({"time": d.strftime("%m-%d"), "price": p, "bb_upper": b_u, "bb_lower": b_l})

        return {
            "id": ticker, "rank": 0, "symbol": ticker.replace('.KS','').replace('.KQ',''), "name": name, "market": market_type,
            "currentPrice": price_val,
            "changePercent": safe_float(round(((cur_p - hist['Close'].iloc[-2]) / hist['Close'].iloc[-2]) * 100, 2)),
            "buyZoneTop": safe_float(round(cur_p * 1.02, 2), price_val), "buyZoneBottom": safe_float(round(cur_p * 0.98, 2), price_val),
            "targetPrice": safe_float(round(cur_p * 1.1, 2), price_val), "aiReason": " + ".join(reasons),
            "score": int(score), "rsi": safe_float(round(cur_rsi, 2)), "history": hist_data, "news": [],
            "financials": {
                "op_margin": safe_float(op_margin), 
                "rev_growth": safe_float(rev_growth), 
                "per": safe_float(per)
            },
            "sector": sector, "rvol": safe_float(round(rvol, 2))
        }
    except: return None

# --- [6] ì£¼ê°„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (ìˆ˜ìµë¥  ê²°ì‚°) ---
def generate_weekly_report(target_date_str):
    print(f"\nğŸ“Š [Weekly] {target_date_str} ê¸°ì¤€ ì£¼ê°„ ì„±ê³¼ ë¶„ì„ ì‹œì‘...")
    
    daily_files = []
    end_date = datetime.strptime(target_date_str, "%Y-%m-%d")
    start_date = end_date - timedelta(days=14)
    
    if not os.path.exists(DAILY_DATA_DIR): 
        os.makedirs(DAILY_DATA_DIR)

    if not os.path.exists(WEEKLY_REPORT_DIR):
        os.makedirs(WEEKLY_REPORT_DIR)

    # daily_files ìˆ˜ì§‘ (ë‚ ì§œìˆœ ì •ë ¬)
    for f in sorted(os.listdir(DAILY_DATA_DIR)):
        if f.endswith('_daily.json'):
            file_date_str = f.split('_')[0]
            try:
                file_date = datetime.strptime(file_date_str, "%Y-%m-%d")
                if start_date <= file_date <= end_date: 
                    daily_files.append(f)
            except: pass
            
    print(f"ğŸ“‚ ë¶„ì„ ëŒ€ìƒ ë°ì¼ë¦¬ íŒŒì¼: {len(daily_files)}ê°œ")
    
    # ì¤‘ë³µ ì œê±° ë¡œì§ (ë”•ì…”ë„ˆë¦¬ ì‚¬ìš©)
    stocks_dict = {} 
    for file in daily_files:
        with open(f"{DAILY_DATA_DIR}/{file}", 'r', encoding='utf-8') as f:
            data = json.load(f)
            rec_date = file.split('_')[0]
            for stock in data.get('stocks', []):
                sid = stock['id']
                if sid not in stocks_dict:
                    stock['buyPrice'] = stock['currentPrice'] 
                    stock['recommendDate'] = rec_date
                    stocks_dict[sid] = stock

    aggregated_stocks = list(stocks_dict.values())
    print(f"ğŸ” ì´ {len(aggregated_stocks)}ê°œì˜ ìœ ë‹ˆí¬ ì¢…ëª© ìˆ˜ìµë¥  ê³„ì‚° ì¤‘...")

    final_results = []
    for i, item in enumerate(aggregated_stocks):
        if i % 10 == 0: time.sleep(1)
        ticker = item['id']
        buy_price = item['buyPrice']
        try:
            stock_info = yf.Ticker(ticker)
            target_dt = datetime.strptime(target_date_str, "%Y-%m-%d")
            hist = stock_info.history(period="6mo")
            if hist.empty: continue
            hist.index = hist.index.tz_localize(None)
            hist_until_target = hist[hist.index.strftime('%Y-%m-%d') <= target_date_str] 
            if not hist_until_target.empty:
                current_price = float(hist_until_target['Close'].iloc[-1])
                return_rate = ((current_price - buy_price) / buy_price) * 100
                new_item = item.copy()
                new_item['currentPrice'] = round(current_price, 2)
                new_item['returnRate'] = round(return_rate, 2)
                final_results.append(new_item)
        except Exception as e: pass 

    us_results = [s for s in final_results if s['market'] == 'US']
    kr_results = [s for s in final_results if s['market'] == 'KR']
    us_results.sort(key=lambda x: x['returnRate'], reverse=True)
    kr_results.sort(key=lambda x: x['returnRate'], reverse=True)
    
    us_top10 = us_results[:10]
    kr_top10 = kr_results[:10]
    for i, item in enumerate(us_top10): item['rank'] = i + 1
    for i, item in enumerate(kr_top10): item['rank'] = i + 1
    top_performers = us_top10 + kr_top10
        
    ms = analyze_market_condition(target_date=target_date_str)
    out = {
        "market_status": ms, 
        "stocks": top_performers,
        "dominant_sectors": [], 
        "timestamp": f"{target_date_str} 08:00:00 (Weekly Report)"
    }
    
    output_path = f"{WEEKLY_REPORT_DIR}/{target_date_str}_weekly.json"
    with open(output_path, 'w', encoding='utf-8') as f: json.dump(out, f, indent=2, ensure_ascii=False, allow_nan=False)
    print(f"\nâœ… ì£¼ê°„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_path}")

# --- [7] ì£¼ê°„ ìˆ˜ìµë¥  ê²°ì‚° ì•Œë¦¼ (í† ìš”ì¼ 5PM) ---
def send_weekly_summary_notification():
    print(f"\nğŸ“¢ [Weekly Summary] ì£¼ê°„ ìˆ˜ìµë¥  ê²°ì‚° ì•Œë¦¼ ì „ì†¡ ì‹œì‘...")
    today_str = (datetime.utcnow() + timedelta(hours=9)).strftime("%Y-%m-%d")
    report_file_path = f"{WEEKLY_REPORT_DIR}/{today_str}_weekly.json"
    
    if not os.path.exists(report_file_path):
        generate_weekly_report(today_str)
        update_history_index()

    title = "ğŸ“Š ì£¼ê°„ ìˆ˜ìµë¥  ê²°ì‚° ë„ì°©"
    body = "ì§€ë‚œ 2ì£¼ê°„ì˜ ì¶”ì²œ ì¢…ëª© ì„±ê³¼ ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆ ì•±ì—ì„œ í•œêµ­/ë¯¸êµ­ Top 10 ìˆ˜ìµë¥ ì„ í™•ì¸í•´ë³´ì„¸ìš”!"
    
    # [ìˆ˜ì •] ë°ì´í„° ì—…ë¡œë“œ í›„ ì•Œë¦¼ ì „ì†¡
    git_push_updates("weekly")
    send_push_notification(title, body)

# --- [ìˆ˜ì •] ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ---
def update_history_index():
    if not os.path.exists(WEEKLY_REPORT_DIR): return
    hl = []
    for f in sorted(os.listdir(WEEKLY_REPORT_DIR), reverse=True):
        if f.endswith('_weekly.json'): 
            d_str = f.split('_')[0]
            hl.append({"date": d_str, "file": f"{WEEKLY_REPORT_DIR}/{f}"})
    with open('history_index.json', 'w', encoding='utf-8') as f: json.dump(hl, f, indent=2, ensure_ascii=False)

# --- [ë°±í•„ ì‹¤í–‰ í•¨ìˆ˜] ---
def run_backfill(start_date, end_date):
    print(f"\nâª Backfill Mode: {start_date} ~ {end_date}")
    start_dt = datetime.strptime(start_date, "%Y-%m-%d")
    end_dt = datetime.strptime(end_date, "%Y-%m-%d")
    if not os.path.exists(DAILY_DATA_DIR): os.makedirs(DAILY_DATA_DIR)
    
    current_dt = start_dt
    while current_dt <= end_dt:
        if current_dt.weekday() >= 5: 
            current_dt += timedelta(days=1)
            continue
        target_str = current_dt.strftime("%Y-%m-%d")
        print(f"\nğŸ“… [Backfill] ì²˜ë¦¬ ì¤‘: {target_str}")
        
        ms = analyze_market_condition(target_date=target_str)
        
        # ì„ì‹œë¡œ ALL ì‹¤í–‰ (ë¡œì§ì€ dailyì™€ ë™ì¼í•˜ê²Œ í˜¸ì¶œ)
        # (ì—¬ê¸°ì„œëŠ” ìƒëµ, ì‹¤ì œë¡œëŠ” analyze_stock í˜¸ì¶œ í•„ìš”)
        
        current_dt += timedelta(days=1)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--mode', type=str, default='daily', help='Execution mode: daily, weekly, weekly_summary, or backfill')
    parser.add_argument('--target', type=str, default='ALL', help='Target market: US, KR, or ALL')
    parser.add_argument('--date', type=str, default=None, help='Target date')
    parser.add_argument('--start', type=str, default=None, help='Backfill start date')
    parser.add_argument('--end', type=str, default=None, help='Backfill end date')
    args = parser.parse_args()
    
    if args.date:
        today_str = args.date
    else:
        today_str = (datetime.utcnow() + timedelta(hours=9)).strftime("%Y-%m-%d")
        
    print(f"ğŸš€ AI ì£¼ì‹ ë¶„ì„ê¸° ê°€ë™ (ëª¨ë“œ: {args.mode}, íƒ€ê²Ÿ: {args.target}, ë‚ ì§œ: {today_str})")

    if args.mode == 'daily':
        if not os.path.exists(DAILY_DATA_DIR): os.makedirs(DAILY_DATA_DIR)
        prev_stock_ids = get_latest_recommendation_ids()
        
        existing_stocks = []
        try:
            with open('todays_recommendation.json', 'r', encoding='utf-8') as f:
                existing_stocks = json.load(f).get('stocks', [])
        except: pass

        ms = analyze_market_condition(target_date=today_str)
        final_stocks = []
        
        if args.target in ['US', 'ALL']:
            sp500 = get_sp500_tickers()
            nasdaq100 = get_nasdaq100_tickers()
            us_tickers = list(set(sp500 + nasdaq100))
            print(f"\nğŸ‡ºğŸ‡¸ ë¯¸êµ­ ë¶„ì„ (ëŒ€ìƒ: {len(us_tickers)}ê°œ)...")
            usc = []
            for i, t in enumerate(us_tickers): 
                d = analyze_stock(t, 'US', target_date=today_str)
                if d: usc.append(d)
            usc.sort(key=lambda x: x['score'], reverse=True)
            ust = usc[:10]
            for i, item in enumerate(ust): item['rank'] = i + 1
            process_news_for_list(ust)
            final_stocks.extend(ust)
        else:
            us_kept = [s for s in existing_stocks if s['market'] == 'US']
            final_stocks.extend(us_kept)

        if args.target in ['KR', 'ALL']:
            kr = get_korea_tickers()
            krc = []
            print(f"\nğŸ‡°ğŸ‡· í•œêµ­ ë¶„ì„ (ëŒ€ìƒ: {len(kr)}ê°œ)...")
            for i, t in enumerate(kr): 
                d = analyze_stock(t, 'KR', target_date=today_str)
                if d: krc.append(d)
            krc.sort(key=lambda x: x['score'], reverse=True)
            krt = krc[:10]
            for i, item in enumerate(krt): item['rank'] = i + 1
            process_news_for_list(krt)
            final_stocks.extend(krt)
        else:
            kr_kept = [s for s in existing_stocks if s['market'] == 'KR']
            final_stocks.extend(kr_kept)
        
        all_sectors = [s['sector'] for s in final_stocks if s['sector'] != 'ê¸°íƒ€']
        dominant_sectors = [item[0] for item in Counter(all_sectors).most_common(2)]
        
        noti_title = "ğŸ”” DailyPick10 ì•Œë¦¼"
        market_name = "ë¯¸êµ­" if args.target == 'US' else ("í•œêµ­" if args.target == 'KR' else "ì „ì²´")
        
        # [ì¤‘ìš”] ì¶”ì²œ ì¢…ëª© ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±
        target_market_stocks = [s for s in final_stocks if s['market'] == args.target] if args.target != 'ALL' else final_stocks

        if target_market_stocks:
            new_stocks = [s['symbol'] for s in target_market_stocks if s['id'] not in prev_stock_ids]
            if new_stocks:
                highlight = ", ".join(new_stocks[:2])
                noti_body = f"ì˜¤ëŠ˜ì˜ {market_name} ì¶”ì²œ: {highlight} ë“± (ì‹ ê·œ {len(new_stocks)}ê±´)"
            else:
                top = ", ".join([s['symbol'] for s in target_market_stocks[:2]])
                noti_body = f"ì˜¤ëŠ˜ì˜ {market_name} ì¶”ì²œ: {top} ë“± (ìˆœìœ„ ë³€ë™)"
        else:
            noti_body = f"ì˜¤ëŠ˜ì˜ {market_name} ì¶”ì²œ ì¢…ëª©ì´ ì—†ìŠµë‹ˆë‹¤. (ì‹œì¥ ê´€ë§ í•„ìš” ğŸ“‰)"

        out = {
            "market_status": ms, "stocks": final_stocks, "dominant_sectors": dominant_sectors, 
            "timestamp": f"{today_str} {datetime.now().strftime('%H:%M:%S')}",
            "notification": { "title": noti_title, "body": noti_body }
        }
        
        with open('todays_recommendation.json', 'w', encoding='utf-8') as f: json.dump(out, f, indent=2, ensure_ascii=False, allow_nan=False)
        with open(f"{DAILY_DATA_DIR}/{today_str}_daily.json", 'w', encoding='utf-8') as f: json.dump(out, f, indent=2, ensure_ascii=False, allow_nan=False)

        # [ìˆ˜ì •] Git ì—…ë¡œë“œ ë¨¼ì € ìˆ˜í–‰ í›„ ì•Œë¦¼ ë°œì†¡
        git_push_updates("daily")
        if noti_body and args.date is None:
            send_push_notification(noti_title, noti_body)
    
    elif args.mode == 'weekly':
        generate_weekly_report(today_str)
        update_history_index()
    
    elif args.mode == 'weekly_summary':
        send_weekly_summary_notification()
    
    elif args.mode == 'backfill':
        if args.start and args.end: run_backfill(args.start, args.end)
    
    elif args.mode == 'update_index':
        update_history_index()

    elif args.mode == 'test_push':
        send_push_notification("ğŸ”” í…ŒìŠ¤íŠ¸ ì•Œë¦¼", "ì´ê²ƒì€ ê°•ì œ ì „ì†¡ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ì…ë‹ˆë‹¤!")

    print(f"\nâœ… ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__": main()